{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svg-attention.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1QQu1bNER3sQTCInJedQe7fSaJYhEiJC_",
      "authorship_tag": "ABX9TyOnMsxgunWI/EfR+2ht7BMh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YossiAsher/abstract-learning-in-image-processing/blob/main/svg_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HwKPOzCFqjv"
      },
      "source": [
        "!pip install svgpathtools\n",
        "import shutil\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO-wZBNsIV5J"
      },
      "source": [
        "svg_zip_link = 'https://drive.google.com/file/d/1i0xmRbSkdSG93RxWKWBDsKBnjtO4zdVG/view?usp=sharing'\n",
        "unsupervised_model_checkpoint_folder = 'https://drive.google.com/drive/folders/1ht1ZbXw6ojfOzzMk-4blrrEhoeK90-RU?usp=sharing'\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import io\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3').files()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pWDe1M2IVoy"
      },
      "source": [
        "def download_file(name, link = None, id = None):\n",
        "  fileId = id if id else link.split('/')[-2]\n",
        "  request = drive_service.get_media(fileId=fileId)\n",
        "  fh = io.BytesIO()\n",
        "  downloader = MediaIoBaseDownload(fh, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "      status, done = downloader.next_chunk()\n",
        "      print(\"Download %d%%\" % int(status.progress() * 100))\n",
        "  fh.seek(0)\n",
        "  with open(name, 'wb') as f:\n",
        "      shutil.copyfileobj(fh, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7CUg9y5bmOO"
      },
      "source": [
        "def download_folder(path, link):\n",
        "  folderId = link.split('/')[-1].split('?')[0]\n",
        "  results = drive_service.list(q=f\"'{folderId}' in parents\").execute()\n",
        "  items = results.get('files', [])\n",
        "  os.mkdir(path)\n",
        "  for i in range(3):\n",
        "    id = items[i][\"id\"]\n",
        "    name = f\"{path}/{items[i]['name']}\"\n",
        "    download_file(name=name, id=id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627sMN_bSdpb"
      },
      "source": [
        "download_file('svg_100.zip', svg_zip_link)\n",
        "download_folder('checkpoint', unsupervised_model_checkpoint_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjE1ylNqS3us"
      },
      "source": [
        "!unzip svg_100.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3kRD8mk6uVS"
      },
      "source": [
        "rm -fr svg_100/paragliding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BME9uUjz69EG"
      },
      "source": [
        "rm -rf svg_100/paragliding-launch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MA93s08PglJ"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoF4YfA-Pjx5"
      },
      "source": [
        "!rm -rf ./logs/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VDurA4iFzOM"
      },
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import uuid\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "import pathlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from svgpathtools import svg2paths, Path, CubicBezier, wsvg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-AGcEAXF_y-"
      },
      "source": [
        "learning_rate = 0.002\n",
        "weight_decay = 0.0001\n",
        "batch_size = 128\n",
        "num_epochs = 500\n",
        "projection_dim = 16\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 8,\n",
        "    projection_dim * 4,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [1024, 512]  # Size of the dense layers of the final classifier\n",
        "dim_size = 144\n",
        "input_shape = (dim_size, 5)\n",
        "num_positions = 10000\n",
        "checkpoint_filepath = \"checkpoint/checkpoint\"\n",
        "dropout_rate = 0\n",
        "num_classes = 2\n",
        "seed = 55\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLQ3b_FnJZML"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, path, files, batch_size, dim_size, line_size = 70, supervised=False, shuffle=True, debug=False):\n",
        "        'Initialization'\n",
        "        self.supervised = supervised\n",
        "        if path:\n",
        "          self.files = glob.glob(path + '/**/*.svg', recursive=True)\n",
        "        else:\n",
        "          self.files = files\n",
        "        self.classes = list(set([f.split('/')[-2] for f in self.files])) if supervised else [0,1]\n",
        "        print(\"files: \", len(self.files))\n",
        "        self.shuffle = shuffle\n",
        "        self.debug = debug\n",
        "        self.batch_size = batch_size\n",
        "        if self.batch_size == -1:\n",
        "          self.batch_size = len(self.files)\n",
        "        self.dim_size = dim_size\n",
        "        self.line_size = line_size\n",
        "        self.intersection_count = 0\n",
        "        self.data = self.__init_data(self.files)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        data_temp = [self.data[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(data_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.debug:\n",
        "          self.fo = str(uuid.uuid1())\n",
        "          self.p = pathlib.Path(self.fo)\n",
        "          os.mkdir(self.p)\n",
        "        \n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.data))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __init_data(self, files):\n",
        "      data = []\n",
        "      for file in files:\n",
        "        paths, attributes = svg2paths(file)\n",
        "        data.append((paths, file))\n",
        "      return data\n",
        "\n",
        "    def __data_generation(self, data_temp):\n",
        "        'Generates data containing batch_size samples' \n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, *input_shape))\n",
        "        y = np.zeros((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, (paths, file) in enumerate(data_temp):\n",
        "            # Store sample\n",
        "            paths, segments, index = self.__normalize_path(paths)\n",
        "            \n",
        "            out = 0\n",
        "            if self.supervised:\n",
        "              class_name = file.split('/')[-2]\n",
        "              out = self.classes.index(class_name)\n",
        "            else:\n",
        "              randon_line, line_segment = self.__get_randon_line()\n",
        "              segments[index] = line_segment\n",
        "              for path in paths:\n",
        "                if len(path.intersect(randon_line)) > 0:\n",
        "                  out = 1            \n",
        "\n",
        "            if self.debug:\n",
        "              paths.append(randon_line)\n",
        "              debug_file = str(self.p / (file.replace(self.path, '').replace('/', '_') + '_' + str(intersect) + '.svg'))\n",
        "              wsvg(paths, filename= debug_file)\n",
        "            \n",
        "            # print(segments)\n",
        "            X[i,] = segments\n",
        "            y[i] = out\n",
        "        return X, y\n",
        "    \n",
        "    def __get_randon_line(self):\n",
        "      x1, y1 = np.random.randint(99, size=2)\n",
        "      x2, y2 = np.random.randint(self.line_size, size=2)\n",
        "      line = Path()\n",
        "      cubic_bezier = CubicBezier(complex(x1,y1), complex(x1,y1), complex(x1 + x2,y1 + y2), complex(x1 + x2,y1 + y2))\n",
        "      line.append(cubic_bezier)\n",
        "      return line, self.__segment_to_array(1,cubic_bezier)\n",
        "\n",
        "    def __normalize_path_rotated(self, paths):\n",
        "      new_paths = []\n",
        "      rad = np.random.randint(360)\n",
        "      for path in paths:\n",
        "        new_path = path.rotated(rad)\n",
        "        new_paths.append(new_path)\n",
        "      return new_paths\n",
        "\n",
        "    def __normalize_path(self, paths):\n",
        "      index = 0\n",
        "      segments = np.zeros(input_shape)\n",
        "      paths = self.__normalize_path_rotated(paths)\n",
        "      max_total, paths = self.__normalize_path_align(paths)\n",
        "      paths = self.__normalize_path_scale(paths, max_total)\n",
        "      for path in paths:\n",
        "        for segment in path:\n",
        "          segments[index,] = self.__segment_to_array(0, segment)\n",
        "          index += 1\n",
        "      return paths, segments, index\n",
        "\n",
        "    def __segment_to_array(self, path_index, segment):\n",
        "      values = [path_index,\n",
        "                self.__complex_to_int(segment.start), \n",
        "                self.__complex_to_int(segment.control1),\n",
        "                self.__complex_to_int(segment.control2), \n",
        "                self.__complex_to_int(segment.end)]\n",
        "      return np.array(values)\n",
        "\n",
        "    def __normalize_path_scale(self, paths, max_total):\n",
        "      new_paths = []\n",
        "      for path in paths:\n",
        "        path = path.scaled(99/max_total, 99/max_total)\n",
        "        new_paths.append(path)\n",
        "      return new_paths\n",
        "\n",
        "    def __normalize_path_align(self, paths):\n",
        "      x_max_total = 0\n",
        "      y_max_total = 0\n",
        "      new_paths = []\n",
        "      for path in paths:\n",
        "        if len(path) > 0:\n",
        "          path = path.scaled(1,-1)\n",
        "          x_min, x_max, y_min ,y_max = path.bbox()\n",
        "          path = path.translated(complex(-x_min,-y_min))\n",
        "          x_min, x_max, y_min ,y_max = path.bbox()\n",
        "          if x_max > x_max_total:\n",
        "            x_max_total = x_max\n",
        "          if y_max > y_max_total:\n",
        "            y_max_total = y_max    \n",
        "          new_paths.append(path)\n",
        "      max_total = max(x_max_total, y_max_total)\n",
        "      return max_total, new_paths\n",
        "\n",
        "    def __complex_to_int(self, compl):\n",
        "      # print(compl)\n",
        "      real = self.__clipping_to_int(compl.real)\n",
        "      imag = self.__clipping_to_int(compl.imag)\n",
        "      return real * 100 + imag\n",
        "    \n",
        "    def __clipping_to_int(self, value):\n",
        "      result = int(value) if int(value) >= 0 and int(value) < 100 else (0 if int(value) < 0 else 99)\n",
        "      return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb7x1w-5c4qb"
      },
      "source": [
        "files = glob.glob('svg_100/**/*.svg', recursive=True)\n",
        "train_files, test_files = train_test_split(files, test_size=0.2, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElQEGbNReIvJ"
      },
      "source": [
        "train_dataset = DataGenerator(path=None, files=train_files, batch_size=batch_size, dim_size=dim_size, supervised=True)\n",
        "test_dataset = DataGenerator(path=None, files=test_files, batch_size=batch_size, dim_size=dim_size, supervised=True)\n",
        "unsupervised_dataset = DataGenerator(path=None, files=files, batch_size=batch_size, dim_size=dim_size, supervised=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkvUyaadGG3V"
      },
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "  for units in hidden_units:\n",
        "    x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mABf0YiyGN-7"
      },
      "source": [
        "class PathEncoder(layers.Layer):\n",
        "  def __init__(self, dim_size, num_positions, projection_dim):\n",
        "    super(PathEncoder, self).__init__()\n",
        "    self.dim_size = dim_size\n",
        "    self.num_positions = num_positions\n",
        "    self.projection_dim = projection_dim\n",
        "    self.path_type_embedding = layers.Embedding(\n",
        "        input_dim=2, output_dim=self.projection_dim *4\n",
        "    )\n",
        "    self.embedding_start = layers.Embedding(\n",
        "        input_dim=self.num_positions, output_dim=self.projection_dim\n",
        "    )\n",
        "    self.embedding_control1 = layers.Embedding(\n",
        "        input_dim=self.num_positions, output_dim=self.projection_dim\n",
        "    )\n",
        "    self.embedding_control2 = layers.Embedding(\n",
        "        input_dim=self.num_positions, output_dim=self.projection_dim\n",
        "    )\n",
        "    self.embedding_end = layers.Embedding(\n",
        "        input_dim=self.num_positions, output_dim=self.projection_dim\n",
        "    )\n",
        "\n",
        "  def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'dim_size': self.dim_size,\n",
        "            'num_positions': self.num_positions,\n",
        "            'projection_dim': self.projection_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "  def call(self, paths):\n",
        "    new_shape = (-1, self.dim_size, self.projection_dim)\n",
        "    t0, t1, t2, t3, t4 = tf.split(paths, num_or_size_splits=5, axis=2)\n",
        "    encoded = tf.concat([tf.reshape(self.embedding_start(t1), new_shape),\n",
        "                        tf.reshape(self.embedding_control1(t2), new_shape),\n",
        "                        tf.reshape(self.embedding_control2(t3), new_shape),\n",
        "                        tf.reshape(self.embedding_end(t4), new_shape)], 2)\n",
        "    path_index = tf.reshape(self.path_type_embedding(t0), (-1, self.dim_size, self.projection_dim*4))\n",
        "    return encoded + path_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19dswK74GbI8"
      },
      "source": [
        "inputs = layers.Input(shape=input_shape)\n",
        "# Encode paths.\n",
        "encoded_paths = PathEncoder(dim_size, num_positions, projection_dim)(inputs)\n",
        "# Create multiple layers of the Transformer block.\n",
        "for _ in range(transformer_layers):\n",
        "    # Layer normalization 1.\n",
        "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_paths)\n",
        "    # Create a multi-head attention layer.\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=projection_dim * 4, dropout=dropout_rate\n",
        "    )(x1, x1)\n",
        "    # Skip connection 1.\n",
        "    x2 = layers.Add()([attention_output, encoded_paths])\n",
        "    # Layer normalization 2.\n",
        "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "    # MLP.\n",
        "    x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=dropout_rate)\n",
        "    # Skip connection 2.\n",
        "    encoded_paths = layers.Add()([x3, x2])\n",
        "\n",
        "# Create a [batch_size, projection_dim] tensor.\n",
        "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_paths)\n",
        "representation = layers.Flatten()(representation)\n",
        "representation = layers.Dropout(dropout_rate)(representation)\n",
        "# Add MLP.\n",
        "features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=dropout_rate)\n",
        "# Classify outputs.\n",
        "logits = layers.Dense(num_classes)(features)\n",
        "# Create the Keras model.\n",
        "unsupervised_model = keras.Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzkLYZamNmIP"
      },
      "source": [
        "# in order to use the unsupervised model checkpoint\n",
        "unsupervised_model.load_weights(checkpoint_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9yGLwa2MO-Z"
      },
      "source": [
        "x = unsupervised_model.layers[-4].output \n",
        "x = layers.Dense(512)(x)\n",
        "predictions = layers.Dense(len(train_dataset.classes))(x)\n",
        "supervised_model = keras.Model(inputs = unsupervised_model.input, outputs = predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr6739IHGl0X"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "unsupervised_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\n",
        "        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
        "    ],\n",
        ")\n",
        "\n",
        "supervised_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\n",
        "        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
        "    ],\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFbDmsZrPx3h"
      },
      "source": [
        "log_dir = \"logs/svg-attention\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQm4K29hmRfy"
      },
      "source": [
        "history = supervised_model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=test_dataset,\n",
        "        epochs=num_epochs,\n",
        "        callbacks=[tensorboard_callback],\n",
        "        workers=16, \n",
        "        use_multiprocessing=True,\n",
        "        max_queue_size=100\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMAdzzmWQSKn"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZs-fuglri4P"
      },
      "source": [
        "!tensorboard dev upload \\\n",
        "  --logdir logs/svg-attention \\\n",
        "  --name \"abstract-learning-in-image-processing-svg-attention\" \\\n",
        "  --one_shot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0QfOBXJ8-ts"
      },
      "source": [
        "# train the unsupervised task\n",
        "\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_filepath,\n",
        "    monitor=\"accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        ")\n",
        "\n",
        "history = unsupervised_model.fit(\n",
        "        unsupervised_dataset,\n",
        "        epochs=num_epochs,\n",
        "        callbacks=[checkpoint_callback],\n",
        "        workers=16, \n",
        "        use_multiprocessing=True,\n",
        "        max_queue_size=100\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}